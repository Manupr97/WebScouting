import requests
import json

def test_ollama():
    """Prueba r√°pida para verificar que Ollama funciona"""
    
    print("üîç Verificando conexi√≥n con Ollama...")
    
    # 1. Verificar que el servicio est√° activo
    try:
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            print("‚úÖ Ollama est√° funcionando")
            
            # Mostrar modelos instalados
            modelos = response.json()
            print("\nüì¶ Modelos disponibles:")
            for modelo in modelos.get('models', []):
                print(f"  - {modelo['name']} ({modelo['size'] // 1024 // 1024} MB)")
        else:
            print("‚ùå Ollama no responde correctamente")
            return False
    except Exception as e:
        print(f"‚ùå No se puede conectar con Ollama: {e}")
        print("\nüí° Soluciones:")
        print("  1. Verifica que Ollama est√© instalado")
        print("  2. Reinicia tu computadora despu√©s de instalar")
        print("  3. Ejecuta 'ollama serve' en una terminal")
        return False
    
    # 2. Hacer una prueba de generaci√≥n
    print("\nü§ñ Probando generaci√≥n de texto...")
    
    try:
        payload = {
            "model": "llama3.2",  # o "phi3:mini" si instalaste ese
            "prompt": "Resume en una frase: El f√∫tbol es el deporte m√°s popular del mundo.",
            "stream": False
        }
        
        response = requests.post(
            "http://localhost:11434/api/generate",
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            respuesta = response.json()
            print(f"‚úÖ Respuesta: {respuesta.get('response', 'Sin respuesta')}")
            return True
        else:
            print(f"‚ùå Error en la generaci√≥n: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"‚ùå Error al generar texto: {e}")
        return False

# Ejecutar test
if __name__ == "__main__":
    print("=== TEST DE OLLAMA ===\n")
    
    if test_ollama():
        print("\nüéâ ¬°Todo funciona correctamente!")
        print("\nAhora puedes usar la integraci√≥n de IA en tu sistema de scouting.")
    else:
        print("\n‚ö†Ô∏è Hay problemas con la configuraci√≥n.")
        print("\nPasos para solucionar:")
        print("1. Aseg√∫rate de haber instalado Ollama")
        print("2. Reinicia VS Code o tu computadora")
        print("3. Ejecuta 'ollama pull llama3.2' en la terminal")